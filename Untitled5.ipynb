{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4IRiW6o3nku"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p9WaYl13pyL"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRogyziW3tR_"
      },
      "source": [
        "download = drive.CreateFile({'id': '1sRUp_jnLMUTBNDiWZYy_qKjjiorDcOt9'})\n",
        "download.GetContentFile('data.zip')\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQZaMY973vG6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mo0pNQZ3wrf"
      },
      "source": [
        "data_dir = 'data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxBPZ0d33yof"
      },
      "source": [
        "import os, random, shutil\n",
        "\n",
        "\n",
        "def make_dir(source, target):\n",
        "    '''\n",
        "    创建和源文件相似的文件路径函数\n",
        "    :param source: 源文件位置\n",
        "    :param target: 目标文件位置\n",
        "    '''\n",
        "    dir_names = os.listdir(source)\n",
        "    for names in dir_names:\n",
        "        for i in ['train', 'valid', 'test']:\n",
        "            path = target + '/' + i + '/' + names\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "\n",
        "\n",
        "def divideTrainValiTest(source, target):\n",
        "    '''\n",
        "        创建和源文件相似的文件路径\n",
        "        :param source: 源文件位置\n",
        "        :param target: 目标文件位置\n",
        "    '''\n",
        "    # 得到源文件下的种类\n",
        "    pic_name = os.listdir(source)\n",
        "    \n",
        "    # 对于每一类里的数据进行操作\n",
        "    for classes in pic_name:\n",
        "        # 得到这一种类的图片的名字\n",
        "        pic_classes_name = os.listdir(os.path.join(source, classes))\n",
        "        random.shuffle(pic_classes_name)\n",
        "        \n",
        "        # 按照8：1：1比例划分\n",
        "        train_list = pic_classes_name[0:int(0.9 * len(pic_classes_name))]\n",
        "        valid_list = pic_classes_name[int(0.9 * len(pic_classes_name)):]\n",
        "        test_list = pic_classes_name[int(0.9 * len(pic_classes_name)):]\n",
        "        \n",
        "        # 对于每个图片，移入到对应的文件夹里面\n",
        "        for train_pic in train_list:\n",
        "            shutil.copyfile(source + '/' + classes + '/' + train_pic, target + '/train/' + classes + '/' + train_pic)\n",
        "        for validation_pic in valid_list:\n",
        "            shutil.copyfile(source + '/' + classes + '/' + validation_pic,\n",
        "                            target + '/valid/' + classes + '/' + validation_pic)\n",
        "        for test_pic in test_list:\n",
        "            shutil.copyfile(source + '/' + classes + '/' + test_pic, target + '/test/' + classes + '/' + test_pic)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filepath = r'data_test'\n",
        "    dist = r'data'\n",
        "    make_dir(filepath, dist)\n",
        "    divideTrainValiTest(filepath, dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iP2BU3331dY"
      },
      "source": [
        "# Training transform includes random rotation and flip to build a more robust model\n",
        "train_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.RandomHorizontalFlip(p=0.4),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "# The validation set will use the same transform as the test set\n",
        "test_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "valid_data = datasets.ImageFolder(data_dir + '/valid', transform=validation_transforms)\n",
        "\n",
        "# Using the image datasets and the trainforms, define the dataloaders\n",
        "# The trainloader will have shuffle=True so that the order of the images do not affect the model\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsONYTyq33_Z"
      },
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 196)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.92)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), weight_decay=0.01, amsgrad=False)\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6fnzRIK354X"
      },
      "source": [
        "# Implement a function for the validation pass\n",
        "def validation(model, validloader, criterion):\n",
        "    valid_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    # change model to work with cuda\n",
        "    model.to('cuda')\n",
        "\n",
        "    # Iterate over data from validloader\n",
        "    for ii, (images, labels) in enumerate(validloader):\n",
        "      \n",
        "        # Change images and labels to work with cuda\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Forward pass image though model for prediction\n",
        "        output = model.forward(images)\n",
        "        # Calculate loss\n",
        "        valid_loss += criterion(output, labels).item()\n",
        "        # Calculate probability\n",
        "        ps = torch.exp(output)\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return valid_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5inXFegm37w4"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXAphpJl3_bI"
      },
      "source": [
        "epochs = 10\n",
        "steps = 0\n",
        "print_every = 40\n",
        "\n",
        "# change to gpu mode\n",
        "model.to('cuda')\n",
        "model.train()\n",
        "for e in range(epochs):\n",
        "\n",
        "    running_loss = 0\n",
        "    \n",
        "    # Iterating over data to carry out training step\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "        steps += 1\n",
        "        \n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "        # zeroing parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward and backward passes\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Carrying out validation step\n",
        "        if steps % print_every == 0:\n",
        "            # setting model to evaluation mode during validation\n",
        "            model.eval()\n",
        "            \n",
        "            # Gradients are turned off as no longer in training\n",
        "            with torch.no_grad():\n",
        "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
        "            \n",
        "            print(f\"No. epochs: {e+1}, \\\n",
        "            Training Loss: {round(running_loss/print_every,3)} \\\n",
        "            Valid Loss: {round(valid_loss/len(validloader),3)} \\\n",
        "            Valid Accuracy: {round(float(accuracy/len(validloader)),3)}\")\n",
        "            \n",
        "            \n",
        "            # Turning training back on\n",
        "            model.train()\n",
        "            lrscheduler.step(accuracy * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaA8tNlF3_5X"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.to('cuda')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        # Get probabilities\n",
        "        outputs = model(images)\n",
        "        # Turn probabilities into predictions\n",
        "        _, predicted_outcome = torch.max(outputs.data, 1)\n",
        "        # Total number of images\n",
        "        total += labels.size(0)\n",
        "        # Count number of cases in which predictions are correct\n",
        "        correct += (predicted_outcome == labels).sum().item()\n",
        "\n",
        "print(f\"Test accuracy of model: {round(100 * correct / total,3)}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMnxkmqH4CKX"
      },
      "source": [
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "classes, c_to_idx = find_classes(data_dir+\"/train\")\n",
        "\n",
        "print(classes, c_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pe8eZGn4Eyg"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from torchvision import transforms\n",
        "#\n",
        "# Create a preprocessing pipeline\n",
        "#\n",
        "preprocess = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.RandomHorizontalFlip(p=0.4),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "a = []\n",
        "te = []\n",
        "for i in range(0,16182):\n",
        "    print(i)\n",
        "    if os.path.exists('test/My Drive/testing_data/'+str(i).zfill(6)+'.jpg'):\n",
        "      te.append(i)\n",
        "      img = image.load_img('test/My Drive/testing_data/'+str(i).zfill(6)+'.jpg', grayscale=False)\n",
        "      img_preprocessed = preprocess(img)\n",
        "      batch_img_cat_tensor = torch.unsqueeze(img_preprocessed, 0)\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "      batch_img_cat_tensor = batch_img_cat_tensor.to(device)\n",
        "      model.eval()\n",
        "      out = model(batch_img_cat_tensor)\n",
        "      _, index = torch.max(out, 1)\n",
        "      percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "      a.append(classes[index[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esPRRuOR4HeY"
      },
      "source": [
        "import csv\n",
        "with open('answer.csv', 'w', newline='') as csvFile:\n",
        "  # 建立 CSV 檔寫入器\n",
        "  writer = csv.writer(csvFile)\n",
        "\n",
        "  writer = csv.writer(csvFile, delimiter=',')\n",
        "\n",
        "  # 寫出標題\n",
        "  writer.writerow(['id','label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTxBTM4y4I_m"
      },
      "source": [
        "import pandas as pd\n",
        "sample = pd.read_csv('answer.csv')\n",
        "sample['id'] = te\n",
        "sample['label'] = a\n",
        "sample.to_csv('sample_cnn.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R7w7ROL4Kdn"
      },
      "source": [
        "from PIL import Image\n",
        "img_cat = Image.open(\"test/My Drive/testing_data/016172.jpg\").convert('RGB')\n",
        "img_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBpgSR-4MSv"
      },
      "source": [
        "from torchvision import transforms\n",
        "preprocess = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                    #transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                         [0.229, 0.224, 0.225])]) \n",
        "img_cat_preprocessed = preprocess(img_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgscHsxG4OeH"
      },
      "source": [
        "batch_img_cat_tensor = torch.unsqueeze(img_cat_preprocessed, 0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_img_cat_tensor = batch_img_cat_tensor.to(device)\n",
        "model.eval()\n",
        "outputs = model.forward(batch_img_cat_tensor)\n",
        "out = model(batch_img_cat_tensor)\n",
        "_, index = torch.max(outputs, 1)\n",
        "index\n",
        "percentage = torch.nn.functional.softmax(outputs, dim=1)[0] * 100\n",
        "print(classes[index[0]], percentage[index[0]].item())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}